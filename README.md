# Adam-AI

Voice assistants are programs on digital devices that listen and respond to verbal commands. A user can say, Whatâ€™s the weather?? and the voice assistant will answer with the weather report for that day and location. They could say, tell me a joke, and the assistant will jump into a tale. The user could even say, play music, and song will be played! Voice assistants are so easy to use that many people forget to stop and WONDER how they work. How do voice assistants understand us? Is it magic? A complex system of codes? An actual person listening on the other end? The answer is less complicated than you might think. The application works like Siri, Google Assistant etc. The U.I of the application is selfexplainable and very minimum. It takes voice as input. The system is being designed in such a way that all the services provided by the mobile devices are accessible by the end user on the user's voice command. In our project we implemented a lot of functions/methods for different functionalities like for playing YouTube videos, searching about anything on the internet or the Wikipedia search roll a dice and flip a coin, search maps, shutdown, restart, logout, send email, send WhatsApp messages to your stated contacts and many more 
functionalities. 


DFD LEVEL 1

![image](https://github.com/RJ17069/Adam-AI/assets/104430062/b0d4710e-f384-49c9-8600-04a04d23bc6c)

DFD LEVEL 2

![image](https://github.com/RJ17069/Adam-AI/assets/104430062/a4367eb0-5a3f-401c-bf2b-82c3e3f5c8d5)


DFD LEVEL 3

![image](https://github.com/RJ17069/Adam-AI/assets/104430062/b707b23c-5563-468c-b9a4-3ab0d555f172)


USE CASE DIAGRAM

![image](https://github.com/RJ17069/Adam-AI/assets/104430062/8aa7585a-52ea-4e22-9853-450bb32c894c)

USER INTERFACE

![image](https://github.com/RJ17069/Adam-AI/assets/104430062/33bb76e5-9d48-40d0-aa05-a368bf1c7d64)



